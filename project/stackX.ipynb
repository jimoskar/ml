{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import sklearn.model_selection as model_selection\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "imp_all_data = pd.read_csv(\"jim_imputed\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "all_data = pd.read_csv('resources/vegard_preprocessed.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "SEED = 42\n",
    "NFOLDS = 5\n",
    "\n",
    "def rmlse(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5\n",
    "\n",
    "def get_oof(clf, kf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = x_train.iloc[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "NUMERIC = [\"latitude\", \"longitude\", \"constructed\", \"area_total\", \"area_living\", \"area_kitchen\", \"rooms\", \n",
    "            \"center_distance\", \"park_distance\", \"metro_distance\", \"square_distance\",\"ballog\", \"bathrooms_total\", \"distr_avg\"]\n",
    "CAT = [ \"district\", \"material\", \"condition\", \"heating\", \"new2\", \"parking\", \"garbage_chute\"]\n",
    "FEATURES = NUMERIC + CAT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "data_train = imp_all_data.loc[imp_all_data.split == 'train']\n",
    "data_test = imp_all_data.loc[imp_all_data.split == 'test']\n",
    "X_train = data_train[FEATURES].copy()\n",
    "X_test = data_test[FEATURES].copy()\n",
    "y = data_train.price.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "X_tr, X_te, y_train, y_test = train_test_split(X_train, y, random_state = SEED, test_size = 0.33, stratify=round(np.log(y)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Run this for submissions\n",
    "X_tr = X_train.copy()\n",
    "X_te = X_test.copy()\n",
    "y_train = y.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "train_idx = X_tr.index\n",
    "test_idx = X_te.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# transforming skewed features\n",
    "from scipy.stats import skew\n",
    "\n",
    "y_train = np.log(y_train / (data_train.iloc[train_idx]).area_total)\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "\n",
    "skewed_feats = X_tr[NUMERIC].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "print(skewed_feats)\n",
    "\n",
    "X_tr[skewed_feats] = np.log1p(X_tr[skewed_feats])\n",
    "X_te[skewed_feats] = np.log1p(X_te[skewed_feats])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['area_total', 'area_living', 'area_kitchen', 'rooms', 'center_distance',\n",
      "       'park_distance', 'metro_distance', 'square_distance', 'ballog',\n",
      "       'bathrooms_total', 'distr_avg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "X_tr = pd.get_dummies(X_tr, columns=CAT)\n",
    "X_te = pd.get_dummies(X_te, columns=CAT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training simpler models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "rf_params = {\n",
    "    'n_estimators' : 100,\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': None,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'max_features': 'auto',\n",
    "    'max_leaf_nodes': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'bootstrap':True,\n",
    "    'oob_score': False,\n",
    "    'n_jobs': None,\n",
    "    'random_state': SEED,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'max_samples': None\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate':0.05,\n",
    "    'loss': 'square',\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "tree_params = {\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators':2000,\n",
    "    'subsample':1.0, \n",
    "    'criterion':'mse', \n",
    "    'min_samples_split':4, \n",
    "    'min_samples_leaf':2, \n",
    "    'min_weight_fraction_leaf':0.0, \n",
    "    'max_depth':9, \n",
    "    'min_impurity_decrease':0.0, \n",
    "    'init':None, \n",
    "    'random_state':42, \n",
    "    'max_features':None,\n",
    "    'alpha':0.9,\n",
    "    'verbose':0,\n",
    "    'max_leaf_nodes':None,\n",
    "    'warm_start':False,\n",
    "    'validation_fraction':0.1,\n",
    "    'n_iter_no_change':None,\n",
    "    'tol':0.0001,\n",
    "    'ccp_alpha': 0.0\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "model1 = RandomForestRegressor(**rf_params)\n",
    "model2 = AdaBoostRegressor(**ada_params)\n",
    "model3 = DecisionTreeRegressor(**tree_params)\n",
    "model4 = LinearRegression()\n",
    "model5 = GradientBoostingRegressor(**gb_params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "kf = KFold(n_splits=NFOLDS, shuffle=True,random_state=SEED) \n",
    "\n",
    "rf_oof_train, rf_oof_test = get_oof(model1, kf, X_tr, y_train, X_te)\n",
    "ada_oof_train, ada_oof_test = get_oof(model2, kf, X_tr, y_train, X_te)\n",
    "tree_oof_train, tree_oof_test = get_oof(model3, kf, X_tr, y_train, X_te)\n",
    "linreg_oof_train, linreg_oof_test = get_oof(model4, kf, X_tr, y_train, X_te)\n",
    "gb_oof_train, gb_oof_test = get_oof(model5, kf, X_tr, y_train, X_te)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training advanced models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "STORAGE = \"sqlite:///vegard_optuna.sqlite\"\n",
    "\n",
    "FEATURES = [\"latitude\", \"longitude\", \"district\", \"constructed\", \"area_total\",\n",
    "            \"rooms\", \"ballog\", \"metro_distance\", \"park_distance\",\n",
    "            \"square_distance\", \"material\", \"condition\", \"heating\", \"stories\",\n",
    "            \"floor\", \"ceiling\", \"bathrooms_total\", \"new\"]\n",
    "        \n",
    "CATEGORICAL_FEATURES = [\"district\", \"material\", \"condition\", \"heating\", \"new\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "data_train2 = all_data.loc[all_data.split == 'train']\n",
    "data_test2 = all_data.loc[all_data.split == 'test']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "X_tr2 = (data_train2[FEATURES]).iloc[train_idx]\n",
    "X_te2 = (data_test2[FEATURES]).iloc[test_idx]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \"\"\"\n\u001b[0;32m-> 3600\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3601\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3586\u001b[0m         new_data = self._mgr.take(\n\u001b[0;32m-> 3587\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3588\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-c98d1f021376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_tr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_te2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "X_tr2 = (data_train2[FEATURES])\n",
    "X_te2 = (data_test2[FEATURES])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "cat_study = optuna.create_study(\n",
    "    storage=STORAGE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    study_name=\"CatBoost-T2\",\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "cat_model = CatBoostRegressor(objective=\"RMSE\", random_seed=SEED, silent=True, thread_count=1, **cat_study.best_params)\n",
    "\n",
    "cat_oof_train, cat_oof_test = get_oof(cat_model, kf, X_tr2, y_train, X_te2)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-11-10 15:06:39,236]\u001b[0m Using an existing study with name 'CatBoost-T2' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "lgb_study = optuna.create_study(\n",
    "    storage=STORAGE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    study_name=\"LightGBM-F4\",\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(metric=\"rmse\", n_estimators=5000, n_jobs=3, **lgb_study.best_params)\n",
    "\n",
    "lgb_oof_train, lgb_oof_test = get_oof(lgb_model, kf, X_tr2, y_train, X_te2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-11-10 15:07:35,544]\u001b[0m Using an existing study with name 'LightGBM-F4' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "x_train = np.concatenate((\n",
    "        rf_oof_train,\n",
    "        ada_oof_train,\n",
    "        tree_oof_train,\n",
    "        linreg_oof_train,\n",
    "        gb_oof_train,\n",
    "        lgb_oof_train,\n",
    "        cat_oof_train\n",
    "    ), axis=1)\n",
    "\n",
    "x_test = np.concatenate((\n",
    "    rf_oof_test,\n",
    "    ada_oof_test,\n",
    "    tree_oof_test,\n",
    "    linreg_oof_test,\n",
    "    gb_oof_test,\n",
    "    lgb_oof_test,\n",
    "    cat_oof_test\n",
    "), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "META_MODEL = lgb.LGBMRegressor(\n",
    "    num_leaves=5,\n",
    "    max_depth=7, \n",
    "    random_state=SEED, \n",
    "    silent=True, \n",
    "    metric='mse',\n",
    "    n_jobs=4, \n",
    "    n_estimators=200,\n",
    "    colsample_bytree=1,\n",
    "    subsample=0.9,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "META_MODEL.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=7,\n",
       "              metric='mse', min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=200, n_jobs=4, num_leaves=5,\n",
       "              objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,\n",
       "              silent=True, subsample=0.9, subsample_for_bin=200000,\n",
       "              subsample_freq=0)"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# XGB meta model.\n",
    "param = {\n",
    "        'max_depth': 3, \n",
    "        'reg_alpha': 0.0012, 'reg_lambda': 0.003, \n",
    "        'min_child_weight': 0, 'gamma': 2, \n",
    "        'learning_rate': 0.0132, 'colsample_bytree': 0.45\n",
    "        }\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "META_MODEL = xgb.train(param, dtrain, num_boost_round=200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "preds = np.exp(META_MODEL.predict(dtest)) * (data_train.iloc[test_idx]).area_total\n",
    "rmlse(y_test, preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8386848920591313"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "preds = np.exp(META_MODEL.predict(x_test)) * data_test.area_total\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = data_test.index\n",
    "submission['price_prediction'] = preds.values\n",
    "submission.to_csv('submissions/stack.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "submission"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23285</td>\n",
       "      <td>3.021545e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23286</td>\n",
       "      <td>9.785289e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23287</td>\n",
       "      <td>6.175348e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23288</td>\n",
       "      <td>8.358377e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23289</td>\n",
       "      <td>5.332597e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>33217</td>\n",
       "      <td>2.835395e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9933</th>\n",
       "      <td>33218</td>\n",
       "      <td>1.921649e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>33219</td>\n",
       "      <td>9.002818e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>33220</td>\n",
       "      <td>8.941344e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>33221</td>\n",
       "      <td>6.698044e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  price_prediction\n",
       "0     23285      3.021545e+07\n",
       "1     23286      9.785289e+06\n",
       "2     23287      6.175348e+06\n",
       "3     23288      8.358377e+06\n",
       "4     23289      5.332597e+06\n",
       "...     ...               ...\n",
       "9932  33217      2.835395e+07\n",
       "9933  33218      1.921649e+07\n",
       "9934  33219      9.002818e+06\n",
       "9935  33220      8.941344e+06\n",
       "9936  33221      6.698044e+06\n",
       "\n",
       "[9937 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "675e4d1f4971b295d587632b2ddd77135b95b56ce96661a1d369a7e57f4b577d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}