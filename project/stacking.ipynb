{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import sklearn.model_selection as model_selection\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers[\"KML\"] = \"rw\"\n",
    "#pd.set_option('display.max_columns', 500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "NFOLDS = 5\n",
    "SEED = 42"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Utils\n",
    "def rmlse(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5\n",
    "\n",
    "def get_oof(clf, kf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = x_train.iloc[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_data = pd.read_csv('resources/data_position_poi.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "all_data['bathrooms_total'] = all_data['bathrooms_private'] + all_data['bathrooms_shared']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "all_data['area_per_room'] = all_data['area_total']/all_data['rooms']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "all_data['ballog'] = all_data['loggias'] + all_data['balconies']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "all_data = pd.get_dummies(all_data, columns = [\"heating\", \"district\", \"condition\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "all_data = all_data.fillna(all_data.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "data = all_data.loc[all_data['split'] == 'train', :]\n",
    "data = data.drop(columns=['split'])\n",
    "\n",
    "data_test = all_data.loc[all_data['split'] == 'test', :]\n",
    "data_test = data_test.drop(columns=['split', 'price'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "rf_params = {\n",
    "    'n_estimators' : 100,\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': None,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'max_features': 'auto',\n",
    "    'max_leaf_nodes': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'bootstrap':True,\n",
    "    'oob_score': False,\n",
    "    'n_jobs': None,\n",
    "    'random_state': SEED,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'max_samples': None\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'num_leaves': 10,\n",
    "    'max_depth': 5, \n",
    "    'random_state':SEED, \n",
    "    'silent' : True, \n",
    "    'metric': 'mse',\n",
    "    'n_jobs': 4, \n",
    "    'n_estimators': 2000,\n",
    "    'colsample_bytree': 0.95,\n",
    "    'subsample': 0.9,\n",
    "    'learning_rate': 0.05\n",
    "}\n",
    "\n",
    "cb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'thread_count': -1,\n",
    "    'depth': 7,\n",
    "    'silent': True,\n",
    "    'random_seed': SEED,\n",
    "    'bagging_temperature': 0.2\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate':0.05,\n",
    "    'loss': 'square',\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "tree_params = {\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': SEED\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def objective(trial, X, y, area):\n",
    "\n",
    "    param = {   'booster': 'gbtree',\n",
    "                'max_depth':trial.suggest_int('max_depth', 1, 11),\n",
    "                'reg_alpha':trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "                'reg_lambda':trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "                'min_child_weight':trial.suggest_int('min_child_weight', 0, 5),\n",
    "                'gamma':trial.suggest_int('gamma', 0, 5),\n",
    "                'learning_rate':trial.suggest_loguniform('learning_rate',0.001,0.5),\n",
    "                'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree',0.1,1,0.01),\n",
    "                'nthread' : -1\n",
    "    }\n",
    "    model1 = RandomForestRegressor(**rf_params)\n",
    "    model2 = lgb.LGBMRegressor(**lgb_params)\n",
    "    model3 = CatBoostRegressor(**cb_params)\n",
    "    model4 = AdaBoostRegressor(**ada_params)\n",
    "    model5 = DecisionTreeRegressor(**tree_params)\n",
    "\n",
    "    #pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-rmse\")\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = np.empty(5)\n",
    "\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        #y_train, y_test = np.log(y[train_idx]/area[train_idx]), np.log(y[test_idx]/area[test_idx])\n",
    "        y_train, y_test = np.log(y[train_idx]), np.log(y[test_idx])\n",
    "\n",
    "        kf = KFold(\n",
    "            n_splits=NFOLDS,\n",
    "            shuffle=True,\n",
    "            random_state=SEED\n",
    "        ) \n",
    "\n",
    "        rf_oof_train, rf_oof_test = get_oof(model1, kf, X_train, y_train, X_test)\n",
    "        lgbm_oof_train, lgbm_oof_test = get_oof(model2, kf, X_train, y_train, X_test)\n",
    "        cb_oof_train, cb_oof_test = get_oof(model3, kf, X_train, y_train, X_test)\n",
    "        ada_oof_train, ada_oof_test = get_oof(model4, kf, X_train, y_train, X_test)\n",
    "        tree_oof_train, tree_oof_test = get_oof(model5, kf, X_train, y_train, X_test)\n",
    "\n",
    "        x_train = np.concatenate((\n",
    "            rf_oof_train,\n",
    "            lgbm_oof_train,\n",
    "            cb_oof_train,\n",
    "            ada_oof_train,\n",
    "            tree_oof_train\n",
    "        ), axis=1)\n",
    "\n",
    "        x_test = np.concatenate((\n",
    "            rf_oof_test,\n",
    "            lgbm_oof_test,\n",
    "            cb_oof_test,\n",
    "            ada_oof_test,\n",
    "            tree_oof_test\n",
    "        ), axis=1)\n",
    "\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "        META_MODEL = xgb.train(param, dtrain, \n",
    "                                num_boost_round=3000, \n",
    "                                evals=[(dtest, \"validation\")], \n",
    "                                early_stopping_rounds = 50, \n",
    "                                verbose_eval= 200)\n",
    "                                #callbacks=[pruning_callback])\n",
    "    \n",
    "        #preds = np.exp(META_MODEL.predict(dtest)) * area[test_idx]\n",
    "        #y_true = np.exp(y_test) * area[test_idx]\n",
    "\n",
    "        preds = np.exp(META_MODEL.predict(dtest))\n",
    "        y_true = np.exp(y_test)\n",
    "        cv_scores[idx] = rmlse(y_true, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "FEATURES = ['area_total', 'rooms', 'longitude', 'latitude', 'area_per_room', \n",
    "        'square_distance', 'park_distance', 'ceiling', 'stories', 'constructed', 'bathrooms_total', 'ballog']\n",
    "district = [col for col in data if col.startswith('district')]\n",
    "FEATURES += district\n",
    "heating = [col for col in data if col.startswith('heating')]\n",
    "FEATURES += heating\n",
    "condition = [col for col in data if col.startswith('condition')]\n",
    "FEATURES += condition\n",
    "print(FEATURES)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['area_total', 'rooms', 'longitude', 'latitude', 'area_per_room', 'square_distance', 'park_distance', 'ceiling', 'stories', 'constructed', 'bathrooms_total', 'ballog', 'district_0.0', 'district_1.0', 'district_2.0', 'district_3.0', 'district_4.0', 'district_5.0', 'district_6.0', 'district_7.0', 'district_8.0', 'district_9.0', 'district_10.0', 'district_11.0', 'heating_0.0', 'heating_1.0', 'heating_2.0', 'heating_3.0', 'condition_0.0', 'condition_1.0', 'condition_2.0', 'condition_3.0']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "\n",
    "X = data[FEATURES]\n",
    "y = data['price']\n",
    "area = data.area_total\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Stack\")\n",
    "func = lambda trial: objective(trial, X, y, area)\n",
    "study.optimize(func, n_trials=10)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-11-06 16:19:06,559]\u001b[0m A new study created in memory with name: Stack\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tvalidation-rmse:15.75510\n",
      "[200]\tvalidation-rmse:1.33181\n",
      "[400]\tvalidation-rmse:0.17726\n",
      "[600]\tvalidation-rmse:0.13877\n",
      "[800]\tvalidation-rmse:0.13836\n",
      "[814]\tvalidation-rmse:0.13830\n",
      "[0]\tvalidation-rmse:15.76713\n",
      "[200]\tvalidation-rmse:1.33566\n",
      "[400]\tvalidation-rmse:0.18087\n",
      "[600]\tvalidation-rmse:0.14167\n",
      "[800]\tvalidation-rmse:0.14096\n",
      "[1000]\tvalidation-rmse:0.14070\n",
      "[1200]\tvalidation-rmse:0.14048\n",
      "[1362]\tvalidation-rmse:0.14045\n",
      "[0]\tvalidation-rmse:15.75126\n",
      "[200]\tvalidation-rmse:1.33358\n",
      "[400]\tvalidation-rmse:0.18064\n",
      "[600]\tvalidation-rmse:0.14223\n",
      "[800]\tvalidation-rmse:0.14182\n",
      "[1000]\tvalidation-rmse:0.14161\n",
      "[1187]\tvalidation-rmse:0.14146\n",
      "[0]\tvalidation-rmse:15.76552\n",
      "[200]\tvalidation-rmse:1.33666\n",
      "[400]\tvalidation-rmse:0.18522\n",
      "[600]\tvalidation-rmse:0.14639\n",
      "[800]\tvalidation-rmse:0.14548\n",
      "[1000]\tvalidation-rmse:0.14522\n",
      "[1200]\tvalidation-rmse:0.14499\n",
      "[1254]\tvalidation-rmse:0.14501\n",
      "[0]\tvalidation-rmse:15.74972\n",
      "[200]\tvalidation-rmse:1.33843\n",
      "[400]\tvalidation-rmse:0.19025\n",
      "[600]\tvalidation-rmse:0.15171\n",
      "[800]\tvalidation-rmse:0.15080\n",
      "[1000]\tvalidation-rmse:0.15038\n",
      "[1064]\tvalidation-rmse:0.15037\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-11-06 16:43:51,144]\u001b[0m Trial 0 finished with value: 0.1431199363304717 and parameters: {'max_depth': 3, 'reg_alpha': 0.01889727643739053, 'reg_lambda': 4.6226696008155217e-08, 'min_child_weight': 1, 'gamma': 0, 'learning_rate': 0.012298141615502864, 'colsample_bytree': 0.71}. Best is trial 0 with value: 0.1431199363304717.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "675e4d1f4971b295d587632b2ddd77135b95b56ce96661a1d369a7e57f4b577d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}