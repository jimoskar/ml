{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "import sklearn.model_selection as model_selection\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers[\"KML\"] = \"rw\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# import data \n",
    "\n",
    "# Read the apartment datasets\n",
    "apartments_train = pd.read_csv(\"resources/data/apartments_train.csv\").set_index(\"id\")\n",
    "apartments_train[\"split\"] = \"train\"\n",
    "apartments_test = pd.read_csv(\"resources/data/apartments_test.csv\").set_index(\"id\")\n",
    "apartments_test[\"split\"] = \"test\"\n",
    "\n",
    "# Create a DataFrame of all apartments\n",
    "apartments = pd.concat([apartments_train, apartments_test])\n",
    "\n",
    "# Read the building datasets\n",
    "buildings_train = pd.read_csv(\"resources/data/buildings_train.csv\").set_index(\"id\")\n",
    "buildings_train[\"split\"] = \"train\"\n",
    "buildings_test = pd.read_csv(\"resources/data/buildings_test.csv\").set_index(\"id\")\n",
    "buildings_test[\"split\"] = \"test\"\n",
    "\n",
    "# Create a GeoDataFrame of all buildings\n",
    "buildings = pd.concat([buildings_train, buildings_test])\n",
    "buildings = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(\n",
    "    buildings.longitude, buildings.latitude, crs=\"EPSG:4326\"\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Find all buildings missing coordinates\n",
    "no_coords = buildings.latitude.isna() | buildings.longitude.isna()\n",
    "street = buildings[~no_coords & (buildings.street == \"пос. Коммунарка\")]\n",
    "\n",
    "buildings.loc[no_coords, \"latitude\"] = street.latitude.mean()\n",
    "buildings.loc[no_coords, \"longitude\"] = street.longitude.mean()\n",
    "buildings.loc[no_coords, \"district\"] = street.district.mode()[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# The coordinates of the southwest and northeast corners of a rectangle approximately encompassing Moscow\n",
    "MOSCOW_SW_LAT = 55\n",
    "MOSCOW_SW_LON = 35\n",
    "MOSCOW_NE_LAT = 57\n",
    "MOSCOW_NE_LON = 39"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Find all buildings with coordinates outside of Moscow\n",
    "outside = (((buildings.latitude < MOSCOW_SW_LAT) | (buildings.latitude > MOSCOW_NE_LAT)\n",
    "          | (buildings.longitude < MOSCOW_SW_LON) | (buildings.longitude > MOSCOW_NE_LON)))\n",
    "buildings[outside][[\"split\", \"latitude\", \"longitude\", \"district\", \"street\", \"address\", \"constructed\", \"material\", \"stories\"]]\n",
    "\n",
    "for idx, building in buildings[outside].iterrows():\n",
    "    street = buildings[~outside & (buildings.street == building.street)]\n",
    "    if len(street):\n",
    "        buildings.loc[idx, \"latitude\"] = street.latitude.mean()\n",
    "        buildings.loc[idx, \"longitude\"] = street.longitude.mean()\n",
    "        buildings.loc[idx, \"district\"] = street.district.mode()[0]\n",
    "    else:\n",
    "        buildings.loc[idx, \"latitude\"] = buildings[~outside].latitude.mean()\n",
    "        buildings.loc[idx, \"longitude\"] = buildings[~outside].longitude.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "no_district = buildings.district.isna()\n",
    "districts = buildings.loc[no_district].apply(\n",
    "    lambda b: buildings.loc[\n",
    "        (buildings[~no_district][[\"latitude\", \"longitude\"]] - b[[\"latitude\", \"longitude\"]]).abs().sum(axis=1).idxmin()\n",
    "    ].district,\n",
    "    axis=1\n",
    ")\n",
    "districts.rename(\"district\", inplace=True)\n",
    "buildings.update(districts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "stations = gpd.read_file(\"resources/metro_stations.kml\", driver=\"KML\").drop(columns=[\"Description\"]).rename(columns={\"Name\": \"name\"})\n",
    "\n",
    "# The Earth's radius in meters\n",
    "EARTH_RADIUS = 6371000\n",
    "\n",
    "# Create temporary columns for coordinates given in radians\n",
    "stations[\"lon_rad\"] = np.radians(stations.geometry.x)\n",
    "stations[\"lat_rad\"] = np.radians(stations.geometry.y)\n",
    "buildings[\"lon_rad\"] = np.radians(buildings.longitude)\n",
    "buildings[\"lat_rad\"] = np.radians(buildings.latitude)\n",
    "\n",
    "# Calculate the distance to the nearest metro station for each building using\n",
    "# the haversine formula with the Earth's radius as given above\n",
    "buildings[\"metro_distance\"] = buildings.apply(\n",
    "    lambda row: np.min(\n",
    "        2\n",
    "        * EARTH_RADIUS\n",
    "        * np.arcsin(\n",
    "            np.sqrt(\n",
    "                np.sin((stations.lat_rad - row.lat_rad) / 2) ** 2\n",
    "                + np.cos(row.lat_rad)\n",
    "                * np.cos(stations.lat_rad)\n",
    "                * np.sin((stations.lon_rad - row.lon_rad) / 2) ** 2\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Read park and garden location data\n",
    "parks = gpd.read_file(\"resources/parks_and_gardens.kml\", driver=\"KML\").drop(columns=[\"Description\"]).rename(columns={\"Name\": \"name\"})\n",
    "\n",
    "# Create columns for coordinates given in radians\n",
    "parks[\"lon_rad\"] = np.radians(parks.geometry.x)\n",
    "parks[\"lat_rad\"] = np.radians(parks.geometry.y)\n",
    "\n",
    "# Calculate the distance to the nearest park or garden for each building using\n",
    "# the haversine formula with the Earth's radius as given above\n",
    "buildings[\"park_distance\"] = buildings.apply(\n",
    "    lambda row: np.min(\n",
    "        2\n",
    "        * EARTH_RADIUS\n",
    "        * np.arcsin(\n",
    "            np.sqrt(\n",
    "                np.sin((parks.lat_rad - row.lat_rad) / 2) ** 2\n",
    "                + np.cos(row.lat_rad)\n",
    "                * np.cos(parks.lat_rad)\n",
    "                * np.sin((parks.lon_rad - row.lon_rad) / 2) ** 2\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Drop the temporary radian columns\n",
    "stations.drop(columns=[\"lon_rad\", \"lat_rad\"], inplace=True)\n",
    "buildings.drop(columns=[\"lon_rad\", \"lat_rad\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "buildings_train = buildings.loc[buildings[\"split\"] == \"train\", :]\n",
    "buildings_train.drop(columns = \"split\", inplace = True)\n",
    "apartments = pd.read_csv('resources/data/apartments_train.csv')\n",
    "data = pd.merge(apartments, buildings_train, how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "buildings_test = buildings.loc[buildings[\"split\"] == \"test\", :]\n",
    "buildings_test.drop(columns = \"split\", inplace = True)\n",
    "apartments_test = pd.read_csv('resources/data/apartments_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test, how='left', left_on='building_id', right_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jimtotland/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "apartments = pd.read_csv('resources/data/apartments_train.csv')\n",
    "buildings = pd.read_csv('resources/data/buildings_train.csv')\n",
    "nan_data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "\n",
    "distance = np.sqrt((37.6 - data[\"longitude\"])**2 + (55.75 - data[\"latitude\"])**2)\n",
    "data[\"distance\"] = distance\n",
    "data_train, data_valid = model_selection.train_test_split(data, test_size=0.33, stratify=np.log(data.price).round())\n",
    "\n",
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5\n",
    "\n",
    "\n",
    "#input_x = test_data[[\"area_total\", \"distance\", \"rooms\", \"norm_const\", \"stories\", \"floor\"]]\n",
    "#in_dist = test_data[[\"district\"]]\n",
    "\n",
    "X_train = data_train[[\"area_total\", \"longitude\", \"latitude\", \"rooms\", \"constructed\", \"district\", \"metro_distance\", \"park_distance\", \"distance\"]]\n",
    "y_train = np.log(data_train.loc[X_train.index].price)\n",
    "X_valid = data_valid[[\"area_total\", \"longitude\", \"latitude\", \"rooms\", \"constructed\", \"district\", \"metro_distance\", \"park_distance\", \"distance\"]]\n",
    "y_valid = np.log(data_valid.loc[X_valid.index].price)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dval = xgb.DMatrix(X_valid)\n",
    "param = {'max_depth': 6, 'eta': 0.2, 'objective': 'reg:squaredlogerror'}\n",
    "num_round = 2000\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds_train = bst.predict(dtrain)\n",
    "preds_valid = bst.predict(dval)\n",
    "\n",
    "\n",
    "print(root_mean_squared_log_error(np.exp(preds_train), np.exp(y_train)))\n",
    "print(root_mean_squared_log_error(np.exp(preds_valid), np.exp(y_valid)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12573095665058143\n",
      "0.16190665411486277\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_apartments = pd.read_csv('resources/data/apartments_test.csv')\n",
    "t_buildings = pd.read_csv('resources/data/buildings_test.csv')\n",
    "test_data_a = pd.merge(t_apartments, t_buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "X_test_nan_a = test_data_a.isna().any(axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_data_a[\"id\"]\n",
    "submission.loc[~X_test_nan, 'price_prediction'] = np.exp(numpy_res) # Predict on non-nan entries\n",
    "submission['price_prediction'].fillna(nn_data[\"price\"].mean(), inplace=True)\n",
    "print(f'Generated {len(submission)} predictions')\n",
    "\n",
    "# Export submission to csv with headers\n",
    "submission.to_csv('xgb_submission.csv', index=False)\n",
    "\n",
    "# Look at submitted csv\n",
    "print('\\nLine count of submission')\n",
    "!wc -l sample_submission.csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "675e4d1f4971b295d587632b2ddd77135b95b56ce96661a1d369a7e57f4b577d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}