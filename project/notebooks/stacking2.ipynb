{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import sklearn.model_selection as model_selection\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import geopandas as gpd\n",
    "\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers[\"KML\"] = \"rw\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "NFOLDS = 5\n",
    "SEED = 42"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def get_oof(clf, kf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = x_train.iloc[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "def rmlse(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# import data \n",
    "\n",
    "# Read the apartment datasets\n",
    "apartments_train = pd.read_csv(\"resources/data/apartments_train.csv\").set_index(\"id\")\n",
    "apartments_train[\"split\"] = \"train\"\n",
    "apartments_test = pd.read_csv(\"resources/data/apartments_test.csv\").set_index(\"id\")\n",
    "apartments_test[\"split\"] = \"test\"\n",
    "\n",
    "# Create a DataFrame of all apartments\n",
    "apartments = pd.concat([apartments_train, apartments_test])\n",
    "\n",
    "# Read the building datasets\n",
    "buildings_train = pd.read_csv(\"resources/data/buildings_train.csv\").set_index(\"id\")\n",
    "buildings_train[\"split\"] = \"train\"\n",
    "buildings_test = pd.read_csv(\"resources/data/buildings_test.csv\").set_index(\"id\")\n",
    "buildings_test[\"split\"] = \"test\"\n",
    "\n",
    "# Create a GeoDataFrame of all buildings\n",
    "buildings = pd.concat([buildings_train, buildings_test])\n",
    "buildings = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(\n",
    "    buildings.longitude, buildings.latitude, crs=\"EPSG:4326\"\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Find all buildings missing coordinates\n",
    "no_coords = buildings.latitude.isna() | buildings.longitude.isna()\n",
    "street = buildings[~no_coords & (buildings.street == \"пос. Коммунарка\")]\n",
    "\n",
    "buildings.loc[no_coords, \"latitude\"] = street.latitude.mean()\n",
    "buildings.loc[no_coords, \"longitude\"] = street.longitude.mean()\n",
    "buildings.loc[no_coords, \"district\"] = street.district.mode()[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# The coordinates of the southwest and northeast corners of a rectangle approximately encompassing Moscow\n",
    "MOSCOW_SW_LAT = 55\n",
    "MOSCOW_SW_LON = 35\n",
    "MOSCOW_NE_LAT = 57\n",
    "MOSCOW_NE_LON = 39"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Find all buildings with coordinates outside of Moscow\n",
    "outside = (((buildings.latitude < MOSCOW_SW_LAT) | (buildings.latitude > MOSCOW_NE_LAT)\n",
    "          | (buildings.longitude < MOSCOW_SW_LON) | (buildings.longitude > MOSCOW_NE_LON)))\n",
    "buildings[outside][[\"split\", \"latitude\", \"longitude\", \"district\", \"street\", \"address\", \"constructed\", \"material\", \"stories\"]]\n",
    "\n",
    "for idx, building in buildings[outside].iterrows():\n",
    "    street = buildings[~outside & (buildings.street == building.street)]\n",
    "    if len(street):\n",
    "        buildings.loc[idx, \"latitude\"] = street.latitude.mean()\n",
    "        buildings.loc[idx, \"longitude\"] = street.longitude.mean()\n",
    "        buildings.loc[idx, \"district\"] = street.district.mode()[0]\n",
    "    else:\n",
    "        buildings.loc[idx, \"latitude\"] = buildings[~outside].latitude.mean()\n",
    "        buildings.loc[idx, \"longitude\"] = buildings[~outside].longitude.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Impute district\n",
    "no_district = buildings.district.isna()\n",
    "districts = buildings.loc[no_district].apply(\n",
    "    lambda b: buildings.loc[\n",
    "        (buildings[~no_district][[\"latitude\", \"longitude\"]] - b[[\"latitude\", \"longitude\"]]).abs().sum(axis=1).idxmin()\n",
    "    ].district,\n",
    "    axis=1\n",
    ")\n",
    "districts.rename(\"district\", inplace=True)\n",
    "buildings.update(districts)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "stations = gpd.read_file(\"resources/metro_stations.kml\", driver=\"KML\").drop(columns=[\"Description\"]).rename(columns={\"Name\": \"name\"})\n",
    "\n",
    "# The Earth's radius in meters\n",
    "EARTH_RADIUS = 6371000\n",
    "\n",
    "# Create temporary columns for coordinates given in radians\n",
    "stations[\"lon_rad\"] = np.radians(stations.geometry.x)\n",
    "stations[\"lat_rad\"] = np.radians(stations.geometry.y)\n",
    "buildings[\"lon_rad\"] = np.radians(buildings.longitude)\n",
    "buildings[\"lat_rad\"] = np.radians(buildings.latitude)\n",
    "\n",
    "# Calculate the distance to the nearest metro station for each building using\n",
    "# the haversine formula with the Earth's radius as given above\n",
    "buildings[\"metro_distance\"] = buildings.apply(\n",
    "    lambda row: np.min(\n",
    "        2\n",
    "        * EARTH_RADIUS\n",
    "        * np.arcsin(\n",
    "            np.sqrt(\n",
    "                np.sin((stations.lat_rad - row.lat_rad) / 2) ** 2\n",
    "                + np.cos(row.lat_rad)\n",
    "                * np.cos(stations.lat_rad)\n",
    "                * np.sin((stations.lon_rad - row.lon_rad) / 2) ** 2\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Read park and garden location data\n",
    "parks = gpd.read_file(\"resources/parks_and_gardens.kml\", driver=\"KML\").drop(columns=[\"Description\"]).rename(columns={\"Name\": \"name\"})\n",
    "\n",
    "# Create columns for coordinates given in radians\n",
    "parks[\"lon_rad\"] = np.radians(parks.geometry.x)\n",
    "parks[\"lat_rad\"] = np.radians(parks.geometry.y)\n",
    "\n",
    "# Calculate the distance to the nearest park or garden for each building using\n",
    "# the haversine formula with the Earth's radius as given above\n",
    "buildings[\"park_distance\"] = buildings.apply(\n",
    "    lambda row: np.min(\n",
    "        2\n",
    "        * EARTH_RADIUS\n",
    "        * np.arcsin(\n",
    "            np.sqrt(\n",
    "                np.sin((parks.lat_rad - row.lat_rad) / 2) ** 2\n",
    "                + np.cos(row.lat_rad)\n",
    "                * np.cos(parks.lat_rad)\n",
    "                * np.sin((parks.lon_rad - row.lon_rad) / 2) ** 2\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Read square location data\n",
    "squares = gpd.read_file(\"resources/squares.kml\", driver=\"KML\").drop(columns=[\"Description\"]).rename(columns={\"Name\": \"name\"})\n",
    "\n",
    "# Create columns for coordinates given in radians\n",
    "squares[\"lon_rad\"] = np.radians(squares.geometry.x)\n",
    "squares[\"lat_rad\"] = np.radians(squares.geometry.y)\n",
    "\n",
    "# Calculate the distance to the nearest square for each building using the\n",
    "# haversine formula with the Earth's radius as given above\n",
    "buildings[\"square_distance\"] = buildings.apply(\n",
    "    lambda row: np.min(\n",
    "        2\n",
    "        * EARTH_RADIUS\n",
    "        * np.arcsin(\n",
    "            np.sqrt(\n",
    "                np.sin((squares.lat_rad - row.lat_rad) / 2) ** 2\n",
    "                + np.cos(row.lat_rad)\n",
    "                * np.cos(squares.lat_rad)\n",
    "                * np.sin((squares.lon_rad - row.lon_rad) / 2) ** 2\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Drop the temporary radian columns\n",
    "stations.drop(columns=[\"lon_rad\", \"lat_rad\"], inplace=True)\n",
    "buildings.drop(columns=[\"lon_rad\", \"lat_rad\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "buildings_train = buildings.loc[buildings[\"split\"] == \"train\", :]\n",
    "buildings_train.drop(columns = \"split\", inplace = True)\n",
    "apartments = pd.read_csv('resources/data/apartments_train.csv')\n",
    "data = pd.merge(apartments, buildings_train, how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "buildings_test = buildings.loc[buildings[\"split\"] == \"test\", :]\n",
    "buildings_test.drop(columns = \"split\", inplace = True)\n",
    "apartments_test = pd.read_csv('resources/data/apartments_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test, how='left', left_on='building_id', right_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jimtotland/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# feature ballog\n",
    "data['ballog'] = data['loggias'] + data['balconies']\n",
    "data_test['ballog'] = data_test['loggias'] + data_test['balconies']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "data['bathrooms_total'] = data['bathrooms_private'] + data['bathrooms_shared']\n",
    "data_test['bathrooms_total'] = data_test['bathrooms_private'] + data_test['bathrooms_shared']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "data['area_per_room'] = data['area_total']/data['rooms']\n",
    "data_test['area_per_room'] = data_test['area_total']/data_test['rooms']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "NUMERIC_FEATURES = [\"latitude\", \"longitude\", \"constructed\", \"area_total\",\n",
    "            \"rooms\", \"ballog\", \"metro_distance\", \"park_distance\",\n",
    "            \"square_distance\", \"stories\", \"floor\", \"ceiling\", \"bathrooms_total\"]\n",
    "CATEGORICAL_FEATURES = [\"district\", \"material\", \"condition\", \"heating\", \"new\", \n",
    "                \"layout\", \"parking\", \"garbage_chute\",]\n",
    "data[CATEGORICAL_FEATURES] = data[CATEGORICAL_FEATURES].astype('category')\n",
    "#data_test[CATEGORICAL_FEATURES] = data_test[CATEGORICAL_FEATURES].astype('category')\n",
    "FEATURES = CATEGORICAL_FEATURES + NUMERIC_FEATURES"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "lgb_params = {\n",
    "    'num_leaves': 10,\n",
    "    'max_depth': 5, \n",
    "    'random_state':SEED, \n",
    "    'silent' : True, \n",
    "    'metric': 'mse',\n",
    "    'n_jobs': 4, \n",
    "    'n_estimators': 2000,\n",
    "    'colsample_bytree': 0.95,\n",
    "    'subsample': 0.9,\n",
    "    'learning_rate': 0.05\n",
    "}\n",
    "\n",
    "cb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.01,\n",
    "    'thread_count': -1,\n",
    "    'depth': 7,\n",
    "    'silent': True,\n",
    "    'random_seed': SEED,\n",
    "    'bagging_temperature': 0.2\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skewed_feats = data[NUMERIC_FEATURES].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "print(skewed_feats)\n",
    "\n",
    "df_scaled = data.copy()\n",
    "df_scaled[skewed_feats] = np.log1p(df_scaled[skewed_feats])\n",
    "\n",
    "df_scaled_test = data_test.copy()\n",
    "df_scaled_test[skewed_feats] = np.log1p(df_scaled_test[skewed_feats])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[FEATURES], data.price, random_state = SEED, test_size = 0.20, stratify=round(np.log(data.price)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "X_train.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "district           float64\n",
       "material           float64\n",
       "condition          float64\n",
       "heating            float64\n",
       "new                float64\n",
       "layout             float64\n",
       "parking            float64\n",
       "garbage_chute      float64\n",
       "latitude           float64\n",
       "longitude          float64\n",
       "constructed        float64\n",
       "area_total         float64\n",
       "rooms              float64\n",
       "ballog             float64\n",
       "metro_distance     float64\n",
       "park_distance      float64\n",
       "square_distance    float64\n",
       "stories            float64\n",
       "floor              float64\n",
       "ceiling            float64\n",
       "bathrooms_total    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "model1 = lgb.LGBMRegressor(**lgb_params)\n",
    "model2 = CatBoostRegressor(**cb_params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED) \n",
    "\n",
    "cb_oof_train, cb_oof_test = get_oof(model2, kf, X_train, y_train, X_test)\n",
    "lgbm_oof_train, lgbm_oof_test = get_oof(model1, kf, X_train, y_train, X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "x_train = np.concatenate((\n",
    "        lgbm_oof_train,\n",
    "        cb_oof_train,\n",
    "    ), axis=1)\n",
    "\n",
    "x_test = np.concatenate((\n",
    "    lgbm_oof_test,\n",
    "    cb_oof_test,\n",
    "), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# XGB meta model.\n",
    "param = {\n",
    "        'max_depth': 3, \n",
    "        'reg_alpha': 0.0012, 'reg_lambda': 0.003, \n",
    "        'min_child_weight': 0, 'gamma': 2, \n",
    "        'learning_rate': 0.0132, 'colsample_bytree': 0.45\n",
    "        }\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label= y_train)\n",
    "META_MODEL = xgb.train(param, dtrain, num_boost_round=2000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "preds = META_MODEL.predict(dtest)\n",
    "#rmlse(y_test, preds)\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] < 0:\n",
    "        preds[i] = 0\n",
    "rmlse(y_test, preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.23223219354876223"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "675e4d1f4971b295d587632b2ddd77135b95b56ce96661a1d369a7e57f4b577d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}